Over the past 80 years, most of algorithmic development has relied on the concept of {\em correct computing}, in particular at the level of the basic compute unit: the arithmetic logical unit (ALU). This has led to incredible advancements in the field of computational architecture as well as operating systems and databases. However, with the rapid rise of machine learning (ML) and artificial intelligence (AI) algorithms, this paradigm is no longer strictly required and energy-efficiency takes a more important role. Almost all ML and AI algorithm are based on numerical approximations of (cost) minimization problems and current research into energy-efficient ML/AI focuses on {\em approximate representations} of numbers. In this note, we will explore the idea of {\em approximate computing} (see \cite{XuMytKim2022a}) starting with the simplest model of approximate additions of two integer numbers.
